{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dd0c1db0f201e283da1f8d73cfa88ace223ecac"
   },
   "source": [
    "# Stock Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b42331824cf0c84e37f09e8f591083b7f840f5f"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Load libraries and global variables](#libraries)\n",
    "3. [Read Data](#read_data)\n",
    "4. [Data Overview](#data_overview)\n",
    "5. [Data Cleaning](#data_cleaning)\n",
    "6. [Feature Engineering](#feature_engineering)\n",
    "7. [Time Series Analysis](#time_series_analysis)\n",
    "8. [Corelation Analysis](#corelation)\n",
    "9. [Data Modelling](#data_modelling)\n",
    "10. [Model Selection](#model_selection)\n",
    "11. [Fetch Data](#fetch_data)\n",
    "12. [Feature Scaling](#feature_scaling)\n",
    "13. [Train-test timestep data creation](#train_test_split)\n",
    "14. [Forecasting](#forecasting)\n",
    "15. [Deep Neural Nets](#dl)\n",
    "16. [Prediction Analysis](#prediction_analysis)\n",
    "17. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "beeb9d513c7c0ed377986f581dd44c3c0537277b"
   },
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "519c963a2fa8eb2498a24379eb3f33fd6036af87"
   },
   "source": [
    "This notebook analyzes content present in the `DIJA 30 Stock Time Series` dataset. It provides detailed insight into the stock trends and also includes a guide to train and fit a LSTM model for stock price prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ed68c03e5e19f899ee7cd395741292434f7bc51"
   },
   "source": [
    "<a id='libraries'></a>\n",
    "## Load libraries and set global options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "dfde0b0416668e31ed98a91a7d4f9a062380012e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "de5c253fa10a01b06ac6326cc4e85b151ad444a8"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "sns.set(rc={'figure.figsize':(20, 20)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "16fe9ec8dac9c30605b078d6b28796ddd94b09fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.5 | packaged by conda-forge | (default, Apr  6 2018, 13:39:56) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "pandas version: 0.23.3\n",
      "matplotlib version: 2.2.2\n",
      "NumPy version: 1.14.5\n",
      "SciPy version: 1.1.0\n",
      "IPython version: 6.4.0\n",
      "scikit-learn version: 0.19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version: 2.1.6\n",
      "tensorflow version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd \n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib \n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np \n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp \n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display \n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn \n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import keras\n",
    "print(\"keras version: {}\".format(keras.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1c2bad9328c349f8465eb61871bfd7367eaa6c3"
   },
   "source": [
    "<a id='read_data'></a>\n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9405007bfee7c44fe010f271fd8f221d72377e6c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_stocks_2006-01-01_to_2018-01-01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6144b316f15b5bea82565ef94b27cd49070983bf"
   },
   "source": [
    "<a id='data_overview'></a>\n",
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "8d1c4a86b92b926dfa02ea0bcbd8bbfacf539ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>77.76</td>\n",
       "      <td>79.35</td>\n",
       "      <td>77.24</td>\n",
       "      <td>79.11</td>\n",
       "      <td>3117200</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>79.49</td>\n",
       "      <td>79.49</td>\n",
       "      <td>78.25</td>\n",
       "      <td>78.71</td>\n",
       "      <td>2558000</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>78.41</td>\n",
       "      <td>78.65</td>\n",
       "      <td>77.56</td>\n",
       "      <td>77.99</td>\n",
       "      <td>2529500</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>78.64</td>\n",
       "      <td>78.90</td>\n",
       "      <td>77.64</td>\n",
       "      <td>78.63</td>\n",
       "      <td>2479500</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>78.50</td>\n",
       "      <td>79.83</td>\n",
       "      <td>78.46</td>\n",
       "      <td>79.02</td>\n",
       "      <td>1845600</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Open  High   Low  Close   Volume Name\n",
       "0  2006-01-03 77.76 79.35 77.24  79.11  3117200  MMM\n",
       "1  2006-01-04 79.49 79.49 78.25  78.71  2558000  MMM\n",
       "2  2006-01-05 78.41 78.65 77.56  77.99  2529500  MMM\n",
       "3  2006-01-06 78.64 78.90 77.64  78.63  2479500  MMM\n",
       "4  2006-01-09 78.50 79.83 78.46  79.02  1845600  MMM"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a038ad1b782eee32a70462555594351aa228ce6"
   },
   "source": [
    "From the website, we find the following information about the columns:\n",
    "\n",
    "- `Date` - Date for which the price is given\n",
    "- `Open` - Price of the stock at market open (In USD)\n",
    "- `High` - Highest price reached in the day\n",
    "- `Low` - Lowest price reached in the day\n",
    "- `Close` - Closing price for the day\n",
    "- `Volume` - Number of shares traded\n",
    "`- `Name` - the stock's ticker name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "789b51a63011011e8a377eb8eb6ca3b868c0b626"
   },
   "source": [
    "Further, the author has mentioned that the data has been collected using the `pandas_datareader` package which fetches data from Google Finance API. This could be a cause for concern as the API has long been deprecated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7a76818db0376f12b4e2c327a3ee7264c6334b6c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_stocks_2006-01-01_to_2018-01-01.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8ee3ab8b42f8c52f36c30a47d50e54167cac719c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93612 entries, 0 to 93611\n",
      "Data columns (total 7 columns):\n",
      "Date      93612 non-null datetime64[ns]\n",
      "Open      93587 non-null float64\n",
      "High      93602 non-null float64\n",
      "Low       93592 non-null float64\n",
      "Close     93612 non-null float64\n",
      "Volume    93612 non-null int64\n",
      "Name      93612 non-null object\n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ce2d262f341fd4b0f547ffc27384a3a1c7cbd72c"
   },
   "outputs": [],
   "source": [
    "df.Date = pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "068e390b075c043a3d1f29542e1db33e42ac8a05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93587.00</td>\n",
       "      <td>93602.00</td>\n",
       "      <td>93592.00</td>\n",
       "      <td>93612.00</td>\n",
       "      <td>93612.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.62</td>\n",
       "      <td>86.39</td>\n",
       "      <td>84.84</td>\n",
       "      <td>85.64</td>\n",
       "      <td>20156670.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>108.15</td>\n",
       "      <td>108.96</td>\n",
       "      <td>107.23</td>\n",
       "      <td>108.12</td>\n",
       "      <td>34421077.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.75</td>\n",
       "      <td>7.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.95</td>\n",
       "      <td>34.29</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.96</td>\n",
       "      <td>5040180.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.04</td>\n",
       "      <td>60.63</td>\n",
       "      <td>59.49</td>\n",
       "      <td>60.05</td>\n",
       "      <td>9701141.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94.00</td>\n",
       "      <td>94.74</td>\n",
       "      <td>93.25</td>\n",
       "      <td>94.01</td>\n",
       "      <td>20752221.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1204.88</td>\n",
       "      <td>1213.41</td>\n",
       "      <td>1191.15</td>\n",
       "      <td>1195.83</td>\n",
       "      <td>843264044.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open     High      Low    Close       Volume\n",
       "count 93587.00 93602.00 93592.00 93612.00     93612.00\n",
       "mean     85.62    86.39    84.84    85.64  20156670.14\n",
       "std     108.15   108.96   107.23   108.12  34421077.71\n",
       "min       6.75     7.17     0.00     6.66         0.00\n",
       "25%      33.95    34.29    33.60    33.96   5040180.50\n",
       "50%      60.04    60.63    59.49    60.05   9701141.50\n",
       "75%      94.00    94.74    93.25    94.01  20752221.50\n",
       "max    1204.88  1213.41  1191.15  1195.83 843264044.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8218ec1bea822871fbdcac087aaec1d1d0cd420"
   },
   "source": [
    "The dataset has some missing values. We will analyze this and see how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "249e57ceb1561f2ad251027a936b2676e108c7d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       0\n",
       "Open      25\n",
       "High      10\n",
       "Low       20\n",
       "Close      0\n",
       "Volume     0\n",
       "Name       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee4ce4406deaaaf9f72c26046d547bb638e0b86e"
   },
   "source": [
    "The `Open` column has the maximum number of null values. Let's find the rows for which the values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1455cb31053c51a7cd55232ded710c766fc6ae99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>201.66</td>\n",
       "      <td>nan</td>\n",
       "      <td>201.17</td>\n",
       "      <td>1833625</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>85.70</td>\n",
       "      <td>nan</td>\n",
       "      <td>85.23</td>\n",
       "      <td>3079797</td>\n",
       "      <td>AXP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>242.46</td>\n",
       "      <td>5777271</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>113.95</td>\n",
       "      <td>4486013</td>\n",
       "      <td>CAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18012</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>110.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>109.19</td>\n",
       "      <td>7561205</td>\n",
       "      <td>CVX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24051</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>45.79</td>\n",
       "      <td>45.84</td>\n",
       "      <td>13622891</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25815</th>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>49.14</td>\n",
       "      <td>0</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>110.14</td>\n",
       "      <td>nan</td>\n",
       "      <td>109.93</td>\n",
       "      <td>6815349</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30091</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>80.39</td>\n",
       "      <td>nan</td>\n",
       "      <td>80.04</td>\n",
       "      <td>12820175</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33111</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>25.69</td>\n",
       "      <td>nan</td>\n",
       "      <td>25.61</td>\n",
       "      <td>30616287</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36131</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>225.50</td>\n",
       "      <td>nan</td>\n",
       "      <td>225.33</td>\n",
       "      <td>1999637</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39151</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.98</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.60</td>\n",
       "      <td>5253318</td>\n",
       "      <td>HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42171</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>144.93</td>\n",
       "      <td>nan</td>\n",
       "      <td>144.67</td>\n",
       "      <td>4355718</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48210</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>133.58</td>\n",
       "      <td>nan</td>\n",
       "      <td>132.72</td>\n",
       "      <td>5440788</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>92.36</td>\n",
       "      <td>nan</td>\n",
       "      <td>91.80</td>\n",
       "      <td>11520329</td>\n",
       "      <td>JPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54250</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>154.85</td>\n",
       "      <td>155.14</td>\n",
       "      <td>4280364</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57269</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>63.51</td>\n",
       "      <td>63.88</td>\n",
       "      <td>11714888</td>\n",
       "      <td>MRK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63308</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>59.12</td>\n",
       "      <td>58.33</td>\n",
       "      <td>59.05</td>\n",
       "      <td>6225907</td>\n",
       "      <td>NKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66328</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>33.16</td>\n",
       "      <td>21982573</td>\n",
       "      <td>PFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69348</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>91.07</td>\n",
       "      <td>nan</td>\n",
       "      <td>90.82</td>\n",
       "      <td>7835661</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72368</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>128.09</td>\n",
       "      <td>1077258</td>\n",
       "      <td>TRV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75388</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>119.34</td>\n",
       "      <td>118.44</td>\n",
       "      <td>118.57</td>\n",
       "      <td>2172327</td>\n",
       "      <td>UTX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78408</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>191.81</td>\n",
       "      <td>3776476</td>\n",
       "      <td>UNH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81428</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>48.57</td>\n",
       "      <td>nan</td>\n",
       "      <td>48.40</td>\n",
       "      <td>28456827</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84448</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.99</td>\n",
       "      <td>6263189</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Open   High    Low  Close    Volume Name\n",
       "2913  2017-07-31   nan 201.66    nan 201.17   1833625  MMM\n",
       "5933  2017-07-31   nan  85.70    nan  85.23   3079797  AXP\n",
       "11972 2017-07-31   nan    nan    nan 242.46   5777271   BA\n",
       "14992 2017-07-31   nan    nan    nan 113.95   4486013  CAT\n",
       "18012 2017-07-31   nan 110.00    nan 109.19   7561205  CVX\n",
       "24051 2017-07-31   nan    nan  45.79  45.84  13622891   KO\n",
       "25815 2012-08-01   nan    nan    nan  49.14         0  DIS\n",
       "27071 2017-07-31   nan 110.14    nan 109.93   6815349  DIS\n",
       "30091 2017-07-31   nan  80.39    nan  80.04  12820175  XOM\n",
       "33111 2017-07-31   nan  25.69    nan  25.61  30616287   GE\n",
       "36131 2017-07-31   nan 225.50    nan 225.33   1999637   GS\n",
       "39151 2017-07-31   nan 149.98    nan 149.60   5253318   HD\n",
       "42171 2017-07-31   nan 144.93    nan 144.67   4355718  IBM\n",
       "48210 2017-07-31   nan 133.58    nan 132.72   5440788  JNJ\n",
       "51230 2017-07-31   nan  92.36    nan  91.80  11520329  JPM\n",
       "54250 2017-07-31   nan    nan 154.85 155.14   4280364  MCD\n",
       "57269 2017-07-31   nan    nan  63.51  63.88  11714888  MRK\n",
       "63308 2017-07-31   nan  59.12  58.33  59.05   6225907  NKE\n",
       "66328 2017-07-31   nan    nan    nan  33.16  21982573  PFE\n",
       "69348 2017-07-31   nan  91.07    nan  90.82   7835661   PG\n",
       "72368 2017-07-31   nan    nan    nan 128.09   1077258  TRV\n",
       "75388 2017-07-31   nan 119.34 118.44 118.57   2172327  UTX\n",
       "78408 2017-07-31   nan    nan    nan 191.81   3776476  UNH\n",
       "81428 2017-07-31   nan  48.57    nan  48.40  28456827   VZ\n",
       "84448 2017-07-31   nan    nan    nan  79.99   6263189  WMT"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Open.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8c23a3c98242a2b8a2942d861cf48a5efc68373"
   },
   "source": [
    "Interesting! The data is missing only for 31 July, 2017. This could be because:\n",
    "- The API had an unexpected error while fetching the data.\n",
    "- The data for this day does not exist in the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9184c3c42d3ab1e1e4cf9696af263b11860014"
   },
   "source": [
    "Let's check the number of `business days` for which the records as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "be3337abd5eca45d174f3fbc09b2e56657a3751d"
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range(start='2006-01-01', end='2018-01-01', freq='B')\n",
    "rng[~rng.isin(df.Date.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c90f54bcf713a39f207d0e1696b1e7fe666945c"
   },
   "source": [
    "There are about 111 days for which the stock price data is missing. This could lead to potential problems with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "c0a574d659fb5c8c9505ecf879e975283682bd0d"
   },
   "outputs": [],
   "source": [
    "df.groupby('Name').count().sort_values('Date', ascending=False)['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "16d106bd2528bdf422f2c11f805b4ceef174e570",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf = df[df.Name == 'AABA']\n",
    "cdf = df[df.Name == 'CAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "b9af5e704942130db8d7b34b3dafb1ba1df2dd22"
   },
   "outputs": [],
   "source": [
    "cdf[~cdf.Date.isin(gdf.Date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5208ca7d33fb7b3c187415637b753e697ae9dcf"
   },
   "source": [
    "Some of the companies(Google, Microsoft, etc.) don't have an entry for the date 2010-04-01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d6bf40c3109f0a95f3b0d84d7163fccb2518243"
   },
   "source": [
    "Let's check if all the listed companies have an entry on each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "bb4e17007be27e4505801d5b6e8415a802166736"
   },
   "outputs": [],
   "source": [
    "# Total number of companies\n",
    "df.Name.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "ea8a176224b261ec6d324ba222aed0a4ee1892bf"
   },
   "outputs": [],
   "source": [
    "df.groupby('Date').Name.unique().apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe090cff2e6b7724f25117c0387d4fcb4450f5a2"
   },
   "source": [
    "This confirms that each company had a stock price entry on each day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46d1fa44270eb820ad7fb4ab2a1573a4137ef60f"
   },
   "source": [
    "<a id='data_cleaning'></a>\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "242de172e852f88f33d799abaa8e1b9a2df456f2"
   },
   "source": [
    "Let us first fill in the null values on date 31 july, 2017 with the values from the previous day(i.e 28th July, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "4db4ef66bb66e8e71df910585697836b6f7d5db3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "#Backfill `Open` column\n",
    "values = np.where(df['2017-07-31']['Open'].isnull(), df['2017-07-28']['Open'], df['2017-07-31']['Open'])\n",
    "df['2017-07-31']= df['2017-07-31'].assign(Open=values.tolist())\n",
    "\n",
    "values = np.where(df['2017-07-31']['Close'].isnull(), df['2017-07-28']['Close'], df['2017-07-31']['Close'])\n",
    "df['2017-07-31']= df['2017-07-31'].assign(Close=values.tolist())\n",
    "\n",
    "values = np.where(df['2017-07-31']['High'].isnull(), df['2017-07-28']['High'], df['2017-07-31']['High'])\n",
    "df['2017-07-31']= df['2017-07-31'].assign(High=values.tolist())\n",
    "\n",
    "values = np.where(df['2017-07-31']['Low'].isnull(), df['2017-07-28']['Low'], df['2017-07-31']['Low'])\n",
    "df['2017-07-31']= df['2017-07-31'].assign(Low=values.tolist())\n",
    "\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "572ccf3b874c62002f4ffb29df59a2dc501dd6fb"
   },
   "outputs": [],
   "source": [
    "df[df.Date == '2017-07-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab5d7d6bd8ad87a4bfafa4974b5621599a68df81"
   },
   "source": [
    "We can confirm that the backfill has worked as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e72fa24efaa832319df9b7c6b767dc2be7676f9f"
   },
   "source": [
    "Simlarly, we noticed that 8 of the 31 stocks have missing data on 1st April, 2014. As done before, we will use the stock prices of the previous day to fill the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "3d80c7b8b0aadc4de7c0614e75401c876f7e1e0f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_data_stocks = ['CSCO','AMZN','INTC','AAPL','MSFT','MRK','GOOGL', 'AABA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "65461907e9ba7588c46968569c7fcddb4f83e116",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "42ad0206aee42d75049dc48bbafe1d55d81de2ad"
   },
   "outputs": [],
   "source": [
    "for stock in missing_data_stocks:\n",
    "    tdf = df[(df.Name == stock) & (df.Date == '2014-03-28')].copy()\n",
    "    tdf.Date = '2014-04-01'\n",
    "    pd.concat([df, tdf])\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "740146fd227a15ba4826e19bfd5866a2d9a441c2"
   },
   "source": [
    "Let's check if the backfill worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a8e2ad35e025c4c1a0d7a9fc818694a96f1ac078"
   },
   "outputs": [],
   "source": [
    "df[(df.Name == 'CSCO') & (df.Date == '2014-04-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "707d950bb21aabba402fbd8aeff95f16400ccf86"
   },
   "source": [
    "Awesome! The backfill has worked for that particular day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c315216a951a646e92895e3d4ac829478d23a79"
   },
   "source": [
    "Finally, there is just one more null record. We will drop that record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "6f9a125f132281deadd695aebb421f90283fb60d"
   },
   "outputs": [],
   "source": [
    "df[df.Open.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "dc660cfd70907b0287d97b6168ea1211d7da6468",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[~((df.Date == '2012-08-01') & (df.Name == 'DIS'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f077ded66d847325455d76268a2d0b4a9517f4ca"
   },
   "source": [
    "Let's perform a quick sanity check for null values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "f8f8f6ed952b9f3447dd729e5227cdfaa06872b3"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cafb5548b25e0355fc3cc9e2903ccd682632d236"
   },
   "source": [
    "We have dealt with all the null values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05e49464c65053b76efaf59cfb581224b5a1ee1c"
   },
   "source": [
    "<a id='feature_engineering'></a>\n",
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "502f173e4ff7c50fca45b12ce070f51d4e5a4e4a"
   },
   "source": [
    "Since we have four values of stock price for each day, let's create a feature called `Price` which is the average of all these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "d4624f4e2c775bf93fe946ce9fc098b9c3cb999b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = (df['High'] + df['Low'] + df['Open'] + df['Close'])/4\n",
    "df = df.assign(Price=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "5cdbc3238a1309da03f00fd32be9a2bcc22889ab"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "96e22be46a7643d723e203674baa888f928a1f2c"
   },
   "outputs": [],
   "source": [
    "df.Price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44f0e29d08e91852afda81700d46f90f716772ad"
   },
   "source": [
    "We can see that 75% of the stocks have a price of under 94$, indicating that the stock market is mostly dominated by the bigger companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c2715f33463f211670bd96848dce4ff2e9af37e"
   },
   "source": [
    "Let's go one step further and compute the daily growth of the stock prices compared to day 1 of the prices(i.e compute cumalative compound growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "9290b65c343e23ad566784bdcbb4a0c00d1db004",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_names = df.Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "4382001bc4d65fe9e9458dda4a1ea1bf76229f2b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_prices = df[df.Date == df.Date.min()].Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "30bae1a6fcb9cd93124f2fef3b34a39494302046",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_mapping = {n : c for n, c in zip(stock_names, day_prices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "2d576b07ed3aee58f34186aaefa2af50ed0bb78f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_mapping = np.array(list(map(lambda x : price_mapping[x], df['Name'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "40e267240f3639095036c09bb00a312ac328268c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Growth'] = df['Price'] / base_mapping - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "3450790156df01bbe9d21556cf00200eb9b15b43"
   },
   "outputs": [],
   "source": [
    "df.Growth.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51273f7e09f3a38a2b635f8b4076f065330651ab"
   },
   "source": [
    "**Inferences**\n",
    "\n",
    "Wow! The worst performing company had a decline of 81% in their shares compared to their first ever opening price and the best company had a whopping 2439% increase in their share price. (_Hint_: EC2 instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92a7db5fd086b660db0bf984e26e5c55f7fec6d4"
   },
   "source": [
    "<a id='time_series_analysis'></a>\n",
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6b3e326cfd4aef3f49ab0f0858fa1d57b20529f"
   },
   "source": [
    "Let's find out the top 5 best and worst performing stocks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "c4927422a3bdaf83d5d6f0db0109b0e813e8260b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_dates = pd.date_range(start='2006-01-01', end='2018-01-01', freq='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "a0450e1b98a58f317e2648f8199ec4e194ca365b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_end_dates = sample_dates[sample_dates.is_year_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "e39acb38c6ae257d9deed325a65e4942de1dddb4"
   },
   "outputs": [],
   "source": [
    "year_end_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "dbd3d846926ca4b77dfc506abc973f6118035cf7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_stocks = df[df.Date == df.Date.max()].sort_values('Growth').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "f519051e74e665883e30cbe3245ce0a986475ac0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_stocks = df[df.Date == df.Date.max()].sort_values('Growth', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "7a2006325607aff3e50734a28d0b4710c70ba537",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws = worst_stocks.Name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "98ff77b398d4e18617044fc71a53a696dce1cee9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = best_stocks.Name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "71bb202a8195bf08067565ea700f46af4a53ee83",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "2561f1040b3becb1dd7e77cbd0147a65d2c221e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "c1cda500706b91edd966298c5466d51163892d85"
   },
   "outputs": [],
   "source": [
    "tdf[tdf.Name.isin(ws)].groupby('Name').Growth.plot(title='Historical trend of worst 5 stocks of 2017', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "7ea50146dd87d258be71657e4631ac24f262da75"
   },
   "outputs": [],
   "source": [
    "tdf[tdf.Name.isin(bs)].groupby('Name').Growth.plot(title='Historical trend of best 5 stocks of 2017', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "037a0e20f36af1ac4536dcc400ba6e1fcacda85b"
   },
   "outputs": [],
   "source": [
    "worst_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "ce36b3ed0819e6dead4507f964ef22f079bd86bb"
   },
   "outputs": [],
   "source": [
    "best_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "832df549d11480c4fc7c7a4d2c28543a14d64ff7"
   },
   "source": [
    "** Question: How much would an investment of 1USD in Google in 2006 increase by in 2017?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f6c9fb18b5e37b03895084267ea2ba2268f8f0"
   },
   "source": [
    "According to the above information, an investment of 1 USD in Google in 2006 would have increased the amount to 393USD in 2017. However, the same investment in General Electric Co would have decreased the amount of 0.49USD.\n",
    "This information could help us create an ideal portfolio of stocks to maximize profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef167f97968835ed9efd933e940ed7a39b2ab041"
   },
   "source": [
    "<a id='corelation'></a>\n",
    "## Corelation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ee5a9679a50261fd928afbabf135d78ded4e5b6"
   },
   "source": [
    "Let us now try to find some corelation between the growth vs time of each stock in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "acd9d9bfb4503593de84af7b1bd4545f365d3f98"
   },
   "outputs": [],
   "source": [
    "corr = df.pivot('Date', 'Name', 'Growth').corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05d5f225edf0b2407662791e5380153bee5f104c"
   },
   "source": [
    "Although we can see some positive and negative corelations, the graph above is very dense. Let's us just focus on high positive and high negative corelations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "45acc66bfafc1152f25b895b44e3df6b3a8c9993",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_corelations(indices):\n",
    "    mapping = {}\n",
    "    for record in indices:\n",
    "        (stock_a, stock_b) = record\n",
    "        value_list = mapping.get(stock_a)\n",
    "        if value_list:\n",
    "            if stock_b not in value_list:\n",
    "                value_list.append(stock_b)\n",
    "                mapping.update({stock_a: value_list})\n",
    "        else:\n",
    "            mapping.update({stock_a: [stock_b]})\n",
    "\n",
    "    return mapping\n",
    "\n",
    "def filter_corelations_positive(corr, threshold=0.9):\n",
    "    indices = np.where(corr > threshold)\n",
    "    indices = [(corr.index[x], corr.columns[y]) for x, y in zip(*indices)\n",
    "                                        if x != y and x < y]\n",
    "    mapping = unique_corelations(indices)\n",
    "    return mapping\n",
    "    \n",
    "def filter_corelations_negative(corr, threshold=-0.8):\n",
    "    indices = np.where(corr < threshold)\n",
    "    indices = [(corr.index[x], corr.columns[y]) for x, y in zip(*indices)\n",
    "                                        if x != y and x < y]\n",
    "    mapping = unique_corelations(indices)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "f00d9a5030d820cf94d4470604b0e7562b03b275"
   },
   "outputs": [],
   "source": [
    "filter_corelations_positive(corr, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "0ff009668eb104dcad92f61665ea5800411f7568"
   },
   "outputs": [],
   "source": [
    "filter_corelations_negative(corr, -0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a468a1390c7687e71851ea85bde3c94d646a5cb6"
   },
   "source": [
    "From the above results, we can note the following:-\n",
    "- There is a **Strong Positive** corelation in the stock growth of GOOGL with MSFT, NKE, etc.\n",
    "- There is a **Weak Negative** corelation in the stock growth of GE with IBM and MCD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0228c07018ef2454ec43a6780151574ff2988380"
   },
   "source": [
    "Let us try to forecast the prices of the Google Stock(GOOGL) and measure how close we came to the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58cff53dced5fc4b25c98ea46468d4ca011f98e0"
   },
   "source": [
    "<a id='data_modelling'></a>\n",
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "3487e6cd62ba03b45de7af1d0260cfbdd7582165",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_df = df[df.Name == 'GOOGL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "941cc380589b1e11864bb3ac7d5776121483fd0a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf = google_df[['Date', 'Price']].sort_values('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b363f0c3f86f6e2ff8be2592f14b2a657dd10db"
   },
   "source": [
    "<a id='model_selection'></a>\n",
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62d8cbd27037325ffce2f3ac26d9d28c59b0e34f"
   },
   "source": [
    "As this is a time-series problem, we can use one of the following models to solve it:\n",
    "- ARIMA/ARMA: Auto-Regressive Moving Average models are a class of model that captures a suite of different standard temporal structures in time series data.\n",
    "- LSTM: Long-Short-Term_memory networks are a form of Recurrent Neural Networks. Few advantages of neural nets are:\n",
    "    - Neural networks can model any non-linear function\n",
    "    - Neural networks give good results without much parameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc3a5b050130cc320614686efa59b2c447ce3fae"
   },
   "source": [
    "Hence, We will choose LSTM's as our model for forecasting stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db04edbf33b60f24118f29a102c2d53d7f298ee6"
   },
   "source": [
    "We will try to predict the `Price` of the Google based on the previous 60 values(i.e stock prices on the previous 30 days) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ef4504c7559f6a5f4c39f7368c20b8731af9398"
   },
   "source": [
    "<a id='fetch_data'></a>\n",
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6222844fd45ab7e9331d19bc8e0e1a9214880aa3"
   },
   "source": [
    "We will only use the `Price` column to forecast the future stock price for simplicity. We will ignore all of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "6a0ce13de00226685e5f1acdc30f356ee9a7409b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = gdf[gdf.Date.dt.year != 2017].Price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "1fb7dd9f2078329b442694410c1a333cc7a143ff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set =  gdf[gdf.Date.dt.year == 2017].Price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "1179234870560563e218af7fc3a8f5a669ef15cd"
   },
   "outputs": [],
   "source": [
    "print(\"Training set size: \",training_set.size)\n",
    "print(\"Test set size: \", test_set.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d453211fd569ef72623658dfc1172f08191d214f"
   },
   "source": [
    "<a id='feature_scaling'></a>\n",
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc33d3703f7c193c42f4fc1e6deb343e8f0570ff"
   },
   "source": [
    "As the amount of stock prices vary by a huge margin, we will scale the prices to be in the 0-1 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "f245afed5ee232bb338f494f089e52d25adab5c1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_uuid": "1f504fd3f19ea73aec161354e7d16a107e40ec4d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "bf8e3bbb47b98bd8f5623d2af51398e2a6ddaca8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_scaled = scaler.fit_transform(training_set.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4913d4842a53cc0350b05548c53ad9a80b1047af"
   },
   "source": [
    "<a id='train_test_split'></a>\n",
    "## Train and Test timestep data creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "42dec87bffa9acac901de35810a8db1936ab7c8b"
   },
   "source": [
    "For training, we will use previous 30 stock values to predict the stock price at time t. For this, we have to create our training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_uuid": "8a066fbc15aa49a92cd63c210a31d7d2936e94b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data(training_set_scaled):\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(30, training_set_scaled.size):\n",
    "        X_train.append(training_set_scaled[i-30: i])\n",
    "        y_train.append(training_set_scaled[i])\n",
    "    # Converting list to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "ef1a96912059565bdeea4d0980e2c20d9f270d6d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = create_train_data(training_set_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8127843bd425ee026f918287934bc844f3956929"
   },
   "source": [
    "Similarly, we'll create our test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "e04452a73f653a40568250533fe2f0274299887a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    X_test = []\n",
    "    inputs = gdf[len(gdf) - len(test_set) - 30:].Price.values\n",
    "    inputs = scaler.transform(inputs.reshape(-1, 1))\n",
    "    for i in range(30, test_set.size+30): # Range of the number of values in the training dataset\n",
    "        X_test.append(inputs[i - 30: i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "c9089c1e5bba2312fe82868fc8c69451d7136ea8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "5071d16948c1663180594b5f1c85f2003dde5d80"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e33b584a3b0a1859a2b7a89bde38ec96e1a094a5"
   },
   "source": [
    "<a id='forecasting'></a>\n",
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "541e8b56ea31ca9f5216319c69c593a598b5c225"
   },
   "source": [
    "Let us first start with a very simple model. We will use a single LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "36e7990175971db1a8ca27ed1d8183ae57226344",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "ae3351a557f249e52b42b84d0dd298514e2c0111",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 10, return_sequences = False, input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Dense(units = 1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d01223de3edc0ec5669ce101703b2b519c28e0b9"
   },
   "source": [
    "We now need to pick the optimizer for our model and a function to measure how well the model is doing i.e loss. We will pick RMSE as the loss function and Sigmoid Gradient Descent(SGD) as our optimizer with default learning rate(i.e 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "0051a10de438992ceaa6d00c339f68eb6811fff7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_and_run(model, epochs=50, batch_size=64):\n",
    "    model.compile(metrics=['accuracy'], optimizer='adam', loss='mean_squared_error')\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=3)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "531fb175886a2a3bff532e14a393c3e0f0afc249",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics_df = pd.DataFrame(data={\"loss\": history.history['loss']})\n",
    "    metrics_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "e4c306915de59f78913938b365dd8ba0083f26f8"
   },
   "outputs": [],
   "source": [
    "simple_model = create_simple_model()\n",
    "history = compile_and_run(simple_model, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "bcd4d571ec472b80f6d73ef981c8568d7b45423e"
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2749a1b9452e194fd7828435e5a27f19eedccf2"
   },
   "source": [
    "Let us now use the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "aea51e8b7691dd3031ef405c58b493f2dbf513d6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(X_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    final_predictions = scaler.inverse_transform(y_pred)\n",
    "    fp = np.ndarray.flatten(final_predictions)\n",
    "    ap = np.ndarray.flatten(test_set)\n",
    "    pdf = pd.DataFrame(data={'Actual': ap, 'Predicted': fp})\n",
    "    ax = pdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "9284d466ddc753b50a46553a00d625776a98afa0"
   },
   "outputs": [],
   "source": [
    "make_predictions(X_test, simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8e6f0e1110e33427bd26c65746d8fc6f439f250"
   },
   "source": [
    "As we can see from the image above, although our model seems to have found some trend in the prices, it it _very_ far away from the actual stock value. Hence, this model cannot be used in a production environment.\n",
    "\n",
    "**Question**: Can we improve this model?\n",
    "\n",
    "Lets find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a986ea6ac5d47437cfb31ca32d5e202cdc10fbb1"
   },
   "source": [
    "<a id='dl'></a>\n",
    "## Deep Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c7f75d5bcc2910094d294280e4045617a47344b"
   },
   "source": [
    "As always, here is the solution to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be08943870f54092d6fb989376e8f61978dc95fd"
   },
   "source": [
    "![DL](https://s14-eu5.ixquick.com/cgi-bin/serveimage?url=https%3A%2F%2Fmemegenerator.net%2Fimg%2Finstances%2F49099937%2Fwe-need-to-go-deeper.jpg&sp=820b593abca83c69cfd8fe7944c66fce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8dd01ed6fdbe4006bf9a2f534142d9619ca18095"
   },
   "source": [
    "Deep neural nets can capture trends over a largely spread dataset and could improve our model.\n",
    "For this problem of forecasting, we will use a stacked LSTM(i.e multiple LSTM layers instead of 1). \n",
    "Further, we will also increase the number of units per LSTM cell to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "b67239d443810760b34c296a5880d2233a7ca170",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dl_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the first LSTM layer\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "\n",
    "    # Adding a second LSTM layer\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    \n",
    "    # Adding a third LSTM layer\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "\n",
    "    # Adding a fourth LSTM layer\n",
    "    model.add(LSTM(units = 50))\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "d55a091a8482e1c79151e54d90c08a9dfafd92fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl_model = create_dl_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "dbe0ae904583382e2f7fa60ac809f50d96828e25"
   },
   "outputs": [],
   "source": [
    "dl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "79e07ed7efd0b999ab9888fd095a50b5cb04f4f0"
   },
   "outputs": [],
   "source": [
    "history = compile_and_run(dl_model, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "a7ac930ea02c55e0aa3c3943202281641094cf1d"
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64dcb927c3bf63ccb3fad92198f9b510c90f0f99"
   },
   "source": [
    "As expected, we see that the overall loss of the model reducing until a minima is reached. After that, the loss just stays constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40b9699a68ed499c3ae50e4ec9b6fbe0aad29f84"
   },
   "source": [
    "<a id='prediction_analysis'></a>\n",
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae06c100bef45dbd5a35fbe892c945622c4ac4b4"
   },
   "source": [
    "Let us try our deep neural net on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "b2a15de7696ee0265e65d2c6e213913c0d4a217f"
   },
   "outputs": [],
   "source": [
    "make_predictions(X_test, dl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4fce276e746db278dacd5e397c22dbd60d74dec7"
   },
   "source": [
    "As we can see, the deep neural net is a significant boost from our simple model. It has determined that the stock price is indeed related to the previous stock prices, and surprisngly, it is very accurate, so much so that at various points it is actually equal to the exact value of the stock on that day!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d1c0fb78ee781d36a50fe35119757c7570cfd81"
   },
   "source": [
    "We could further improve this model by:\n",
    "\n",
    "- **Deeper network** - Deep Neural Networks can learn relationships between data points seperated by a large time frame.\n",
    "- **Dropout** - Adding a dropout layer would help prevent overfitting and stabalize the loss curves, which could give a better generalized model.\n",
    "- **Training for longer** - Deep neural nets work better when they are trained for longer tend to work better. However, we must be careful not to overfit.\n",
    "- **Adaptive Optimizers** - We could also use the Adam optimizer instead of SGD, which incorporates adaptive learning rates based on momentum. Adaptive optimizers should work better than SGD for this problem.\n",
    "- **Hyper-parameter tuning** - Tuning the hyper-parameters is one of the simplest ways in which we can improve the network. We could use SGD with Restarts(part of the Fast.ai library) to help find the optimal learning rate, experiment with the number of units in each LSTM layer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ada83ba0cb04a96608f3eeab1cd8f42f254e733"
   },
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10686701a6c55384bc475789d8f7306fa81a7d78"
   },
   "source": [
    "In this notebook, we have acheived the following:\n",
    "- Successfully analyzed the trends present in stock market prices of various companies and concluded that there is indeed a temporal relationship between these prices. \n",
    "- Devised a model capable of reliably forecasting the stock prices of a company, thereby providing a tool to maximize profits.\n",
    "- Discussed possible implementation details to deploy such a model at scale and make it available to a larger number of people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab0b4973de7bfc273a4cb75d3e120e456a60be04"
   },
   "source": [
    "Please let me know about the areas where the solution could be improved. As always, please upvote the kernel if you find it useful. Cheers! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
