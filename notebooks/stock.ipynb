{"cells":[{"metadata":{"_uuid":"0dd0c1db0f201e283da1f8d73cfa88ace223ecac"},"cell_type":"markdown","source":"# Stock Analysis"},{"metadata":{"_uuid":"7b42331824cf0c84e37f09e8f591083b7f840f5f"},"cell_type":"markdown","source":"## Table of Contents\n\n1. [Introduction](#intro)\n2. [Load libraries and global variables](#libraries)\n3. [Read Data](#read_data)\n4. [Data Overview](#data_overview)\n5. [Data Cleaning](#data_cleaning)\n6. [Feature Engineering](#feature_engineering)\n7. [Time Series Analysis](#time_series_analysis)\n8. [Corelation Analysis](#corelation)\n9. [Data Modelling](#data_modelling)\n10. [Model Selection](#model_selection)\n11. [Fetch Data](#fetch_data)\n12. [Feature Scaling](#feature_scaling)\n13. [Train-test timestep data creation](#train_test_split)\n14. [Forecasting](#forecasting)\n15. [Deep Neural Nets](#dl)\n16. [Prediction Analysis](#prediction_analysis)\n17. [Conclusion](#conclusion)"},{"metadata":{"_uuid":"beeb9d513c7c0ed377986f581dd44c3c0537277b"},"cell_type":"markdown","source":"<a id='intro'></a>\n## Introduction"},{"metadata":{"_uuid":"519c963a2fa8eb2498a24379eb3f33fd6036af87"},"cell_type":"markdown","source":"This notebook analyzes content present in the `DIJA 30 Stock Time Series` dataset. It provides detailed insight into the stock trends and also includes a guide to train and fit a LSTM model for stock price prediction."},{"metadata":{"_uuid":"7ed68c03e5e19f899ee7cd395741292434f7bc51"},"cell_type":"markdown","source":"<a id='libraries'></a>\n## Load libraries and set global options"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dfde0b0416668e31ed98a91a7d4f9a062380012e"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"de5c253fa10a01b06ac6326cc4e85b151ad444a8"},"cell_type":"code","source":"pd.options.display.float_format = '{:.2f}'.format\nsns.set(rc={'figure.figsize':(20, 20)})","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16fe9ec8dac9c30605b078d6b28796ddd94b09fa"},"cell_type":"code","source":"import sys\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd \nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport matplotlib \nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\nimport numpy as np \nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp \nprint(\"SciPy version: {}\". format(sp.__version__)) \n\nimport IPython\nfrom IPython import display \nprint(\"IPython version: {}\". format(IPython.__version__)) \n\nimport sklearn \nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\nimport keras\nprint(\"keras version: {}\".format(keras.__version__))\n\nimport tensorflow as tf\nprint(\"tensorflow version: {}\".format(tf.__version__))","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"b1c2bad9328c349f8465eb61871bfd7367eaa6c3"},"cell_type":"markdown","source":"<a id='read_data'></a>\n## Read Data"},{"metadata":{"trusted":true,"_uuid":"9405007bfee7c44fe010f271fd8f221d72377e6c","collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/all_stocks_2006-01-01_to_2018-01-01.csv')","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"6144b316f15b5bea82565ef94b27cd49070983bf"},"cell_type":"markdown","source":"<a id='data_overview'></a>\n## Data Overview"},{"metadata":{"trusted":true,"_uuid":"8d1c4a86b92b926dfa02ea0bcbd8bbfacf539ce0"},"cell_type":"code","source":"df.head()","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"5a038ad1b782eee32a70462555594351aa228ce6"},"cell_type":"markdown","source":"From the website, we find the following information about the columns:\n\n- `Date` - Date for which the price is given\n- `Open` - Price of the stock at market open (In USD)\n- `High` - Highest price reached in the day\n- `Low` - Lowest price reached in the day\n- `Close` - Closing price for the day\n- `Volume` - Number of shares traded\n`- `Name` - the stock's ticker name"},{"metadata":{"_uuid":"789b51a63011011e8a377eb8eb6ca3b868c0b626"},"cell_type":"markdown","source":"Further, the author has mentioned that the data has been collected using the `pandas_datareader` package which fetches data from Google Finance API. This could be a cause for concern as the API has long been deprecated."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7a76818db0376f12b4e2c327a3ee7264c6334b6c"},"cell_type":"code","source":"df = pd.read_csv('../input/all_stocks_2006-01-01_to_2018-01-01.csv', parse_dates=['Date'])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ee3ab8b42f8c52f36c30a47d50e54167cac719c"},"cell_type":"code","source":"df.info()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ce2d262f341fd4b0f547ffc27384a3a1c7cbd72c"},"cell_type":"code","source":"df.Date = pd.to_datetime(df.Date)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"068e390b075c043a3d1f29542e1db33e42ac8a05"},"cell_type":"code","source":"df.describe()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"a8218ec1bea822871fbdcac087aaec1d1d0cd420"},"cell_type":"markdown","source":"The dataset has some missing values. We will analyze this and see how to fix it."},{"metadata":{"trusted":true,"_uuid":"249e57ceb1561f2ad251027a936b2676e108c7d1"},"cell_type":"code","source":"df.isnull().sum()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"ee4ce4406deaaaf9f72c26046d547bb638e0b86e"},"cell_type":"markdown","source":"The `Open` column has the maximum number of null values. Let's find the rows for which the values are missing."},{"metadata":{"trusted":true,"_uuid":"1455cb31053c51a7cd55232ded710c766fc6ae99"},"cell_type":"code","source":"df[df.Open.isnull()]","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"d8c23a3c98242a2b8a2942d861cf48a5efc68373"},"cell_type":"markdown","source":"Interesting! The data is missing only for 31 July, 2017. This could be because:\n- The API had an unexpected error while fetching the data.\n- The data for this day does not exist in the source."},{"metadata":{"_uuid":"3f9184c3c42d3ab1e1e4cf9696af263b11860014"},"cell_type":"markdown","source":"Let's check the number of `business days` for which the records as missing."},{"metadata":{"trusted":true,"_uuid":"be3337abd5eca45d174f3fbc09b2e56657a3751d"},"cell_type":"code","source":"rng = pd.date_range(start='2006-01-01', end='2018-01-01', freq='B')\nrng[~rng.isin(df.Date.unique())]","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"8c90f54bcf713a39f207d0e1696b1e7fe666945c"},"cell_type":"markdown","source":"There are about 111 days for which the stock price data is missing. This could lead to potential problems with the analysis."},{"metadata":{"trusted":true,"_uuid":"c0a574d659fb5c8c9505ecf879e975283682bd0d"},"cell_type":"code","source":"df.groupby('Name').count().sort_values('Date', ascending=False)['Date']","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"16d106bd2528bdf422f2c11f805b4ceef174e570"},"cell_type":"code","source":"gdf = df[df.Name == 'AABA']\ncdf = df[df.Name == 'CAT']","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9af5e704942130db8d7b34b3dafb1ba1df2dd22"},"cell_type":"code","source":"cdf[~cdf.Date.isin(gdf.Date)]","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"a5208ca7d33fb7b3c187415637b753e697ae9dcf"},"cell_type":"markdown","source":"Some of the companies(Google, Microsoft, etc.) don't have an entry for the date 2010-04-01."},{"metadata":{"_uuid":"8d6bf40c3109f0a95f3b0d84d7163fccb2518243"},"cell_type":"markdown","source":"Let's check if all the listed companies have an entry on each date."},{"metadata":{"trusted":true,"_uuid":"bb4e17007be27e4505801d5b6e8415a802166736"},"cell_type":"code","source":"# Total number of companies\ndf.Name.unique().size","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea8a176224b261ec6d324ba222aed0a4ee1892bf"},"cell_type":"code","source":"df.groupby('Date').Name.unique().apply(len)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"fe090cff2e6b7724f25117c0387d4fcb4450f5a2"},"cell_type":"markdown","source":"This confirms that each company had a stock price entry on each day."},{"metadata":{"_uuid":"46d1fa44270eb820ad7fb4ab2a1573a4137ef60f"},"cell_type":"markdown","source":"<a id='data_cleaning'></a>\n## Data Cleaning"},{"metadata":{"_uuid":"242de172e852f88f33d799abaa8e1b9a2df456f2"},"cell_type":"markdown","source":"Let us first fill in the null values on date 31 july, 2017 with the values from the previous day(i.e 28th July, 2017)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4db4ef66bb66e8e71df910585697836b6f7d5db3"},"cell_type":"code","source":"df.set_index('Date', inplace=True)\n\n#Backfill `Open` column\nvalues = np.where(df['2017-07-31']['Open'].isnull(), df['2017-07-28']['Open'], df['2017-07-31']['Open'])\ndf['2017-07-31']= df['2017-07-31'].assign(Open=values.tolist())\n\nvalues = np.where(df['2017-07-31']['Close'].isnull(), df['2017-07-28']['Close'], df['2017-07-31']['Close'])\ndf['2017-07-31']= df['2017-07-31'].assign(Close=values.tolist())\n\nvalues = np.where(df['2017-07-31']['High'].isnull(), df['2017-07-28']['High'], df['2017-07-31']['High'])\ndf['2017-07-31']= df['2017-07-31'].assign(High=values.tolist())\n\nvalues = np.where(df['2017-07-31']['Low'].isnull(), df['2017-07-28']['Low'], df['2017-07-31']['Low'])\ndf['2017-07-31']= df['2017-07-31'].assign(Low=values.tolist())\n\ndf.reset_index(inplace=True)\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"572ccf3b874c62002f4ffb29df59a2dc501dd6fb"},"cell_type":"code","source":"df[df.Date == '2017-07-31']","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"ab5d7d6bd8ad87a4bfafa4974b5621599a68df81"},"cell_type":"markdown","source":"We can confirm that the backfill has worked as expected."},{"metadata":{"_uuid":"e72fa24efaa832319df9b7c6b767dc2be7676f9f"},"cell_type":"markdown","source":"Simlarly, we noticed that 8 of the 31 stocks have missing data on 1st April, 2014. As done before, we will use the stock prices of the previous day to fill the data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3d80c7b8b0aadc4de7c0614e75401c876f7e1e0f"},"cell_type":"code","source":"missing_data_stocks = ['CSCO','AMZN','INTC','AAPL','MSFT','MRK','GOOGL', 'AABA']","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"65461907e9ba7588c46968569c7fcddb4f83e116"},"cell_type":"code","source":"columns = df.columns.values","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42ad0206aee42d75049dc48bbafe1d55d81de2ad"},"cell_type":"code","source":"for stock in missing_data_stocks:\n    tdf = df[(df.Name == stock) & (df.Date == '2014-03-28')].copy()\n    tdf.Date = '2014-04-01'\n    pd.concat([df, tdf])\nprint(\"Complete\")","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"740146fd227a15ba4826e19bfd5866a2d9a441c2"},"cell_type":"markdown","source":"Let's check if the backfill worked as expected."},{"metadata":{"trusted":true,"_uuid":"a8e2ad35e025c4c1a0d7a9fc818694a96f1ac078"},"cell_type":"code","source":"df[(df.Name == 'CSCO') & (df.Date == '2014-04-01')]","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"707d950bb21aabba402fbd8aeff95f16400ccf86"},"cell_type":"markdown","source":"Awesome! The backfill has worked for that particular day"},{"metadata":{"_uuid":"5c315216a951a646e92895e3d4ac829478d23a79"},"cell_type":"markdown","source":"Finally, there is just one more null record. We will drop that record."},{"metadata":{"trusted":true,"_uuid":"6f9a125f132281deadd695aebb421f90283fb60d"},"cell_type":"code","source":"df[df.Open.isnull()]","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dc660cfd70907b0287d97b6168ea1211d7da6468"},"cell_type":"code","source":"df = df[~((df.Date == '2012-08-01') & (df.Name == 'DIS'))]","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"f077ded66d847325455d76268a2d0b4a9517f4ca"},"cell_type":"markdown","source":"Let's perform a quick sanity check for null values again."},{"metadata":{"trusted":true,"_uuid":"f8f8f6ed952b9f3447dd729e5227cdfaa06872b3"},"cell_type":"code","source":"df.isnull().sum()","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"cafb5548b25e0355fc3cc9e2903ccd682632d236"},"cell_type":"markdown","source":"We have dealt with all the null values in the dataset."},{"metadata":{"_uuid":"05e49464c65053b76efaf59cfb581224b5a1ee1c"},"cell_type":"markdown","source":"<a id='feature_engineering'></a>\n## Feature Engineering "},{"metadata":{"_uuid":"502f173e4ff7c50fca45b12ce070f51d4e5a4e4a"},"cell_type":"markdown","source":"Since we have four values of stock price for each day, let's create a feature called `Price` which is the average of all these values."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d4624f4e2c775bf93fe946ce9fc098b9c3cb999b"},"cell_type":"code","source":"values = (df['High'] + df['Low'] + df['Open'] + df['Close'])/4\ndf = df.assign(Price=values)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cdbc3238a1309da03f00fd32be9a2bcc22889ab"},"cell_type":"code","source":"df.head()","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96e22be46a7643d723e203674baa888f928a1f2c"},"cell_type":"code","source":"df.Price.describe()","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"44f0e29d08e91852afda81700d46f90f716772ad"},"cell_type":"markdown","source":"We can see that 75% of the stocks have a price of under 94$, indicating that the stock market is mostly dominated by the bigger companies."},{"metadata":{"_uuid":"5c2715f33463f211670bd96848dce4ff2e9af37e"},"cell_type":"markdown","source":"Let's go one step further and compute the daily growth of the stock prices compared to day 1 of the prices(i.e compute cumalative compound growth)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9290b65c343e23ad566784bdcbb4a0c00d1db004"},"cell_type":"code","source":"stock_names = df.Name.unique()","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4382001bc4d65fe9e9458dda4a1ea1bf76229f2b"},"cell_type":"code","source":"day_prices = df[df.Date == df.Date.min()].Price","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"30bae1a6fcb9cd93124f2fef3b34a39494302046"},"cell_type":"code","source":"price_mapping = {n : c for n, c in zip(stock_names, day_prices)}","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2d576b07ed3aee58f34186aaefa2af50ed0bb78f"},"cell_type":"code","source":"base_mapping = np.array(list(map(lambda x : price_mapping[x], df['Name'].values)))","execution_count":35,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"40e267240f3639095036c09bb00a312ac328268c"},"cell_type":"code","source":"df['Growth'] = df['Price'] / base_mapping - 1","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3450790156df01bbe9d21556cf00200eb9b15b43"},"cell_type":"code","source":"df.Growth.describe()","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"51273f7e09f3a38a2b635f8b4076f065330651ab"},"cell_type":"markdown","source":"**Inferences**\n\nWow! The worst performing company had a decline of 81% in their shares compared to their first ever opening price and the best company had a whopping 2439% increase in their share price. (_Hint_: EC2 instances)"},{"metadata":{"_uuid":"92a7db5fd086b660db0bf984e26e5c55f7fec6d4"},"cell_type":"markdown","source":"<a id='time_series_analysis'></a>\n## Time Series Analysis"},{"metadata":{"_uuid":"f6b3e326cfd4aef3f49ab0f0858fa1d57b20529f"},"cell_type":"markdown","source":"Let's find out the top 5 best and worst performing stocks!"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c4927422a3bdaf83d5d6f0db0109b0e813e8260b"},"cell_type":"code","source":"sample_dates = pd.date_range(start='2006-01-01', end='2018-01-01', freq='B')","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a0450e1b98a58f317e2648f8199ec4e194ca365b"},"cell_type":"code","source":"year_end_dates = sample_dates[sample_dates.is_year_end]","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e39acb38c6ae257d9deed325a65e4942de1dddb4"},"cell_type":"code","source":"year_end_dates","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dbd3d846926ca4b77dfc506abc973f6118035cf7"},"cell_type":"code","source":"worst_stocks = df[df.Date == df.Date.max()].sort_values('Growth').head(5)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f519051e74e665883e30cbe3245ce0a986475ac0"},"cell_type":"code","source":"best_stocks = df[df.Date == df.Date.max()].sort_values('Growth', ascending=False).head(5)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7a2006325607aff3e50734a28d0b4710c70ba537"},"cell_type":"code","source":"ws = worst_stocks.Name.values","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"98ff77b398d4e18617044fc71a53a696dce1cee9"},"cell_type":"code","source":"bs = best_stocks.Name.values","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"71bb202a8195bf08067565ea700f46af4a53ee83"},"cell_type":"code","source":"tdf = df.copy()","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2561f1040b3becb1dd7e77cbd0147a65d2c221e5"},"cell_type":"code","source":"tdf = df.set_index('Date')","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1cda500706b91edd966298c5466d51163892d85"},"cell_type":"code","source":"tdf[tdf.Name.isin(ws)].groupby('Name').Growth.plot(title='Historical trend of worst 5 stocks of 2017', legend=True)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ea50146dd87d258be71657e4631ac24f262da75"},"cell_type":"code","source":"tdf[tdf.Name.isin(bs)].groupby('Name').Growth.plot(title='Historical trend of best 5 stocks of 2017', legend=True)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"037a0e20f36af1ac4536dcc400ba6e1fcacda85b"},"cell_type":"code","source":"worst_stocks","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce36b3ed0819e6dead4507f964ef22f079bd86bb"},"cell_type":"code","source":"best_stocks","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"832df549d11480c4fc7c7a4d2c28543a14d64ff7"},"cell_type":"markdown","source":"** Question: How much would an investment of 1USD in Google in 2006 increase by in 2017?**"},{"metadata":{"_uuid":"a8f6c9fb18b5e37b03895084267ea2ba2268f8f0"},"cell_type":"markdown","source":"According to the above information, an investment of 1 USD in Google in 2006 would have increased the amount to 393USD in 2017. However, the same investment in General Electric Co would have decreased the amount of 0.49USD.\nThis information could help us create an ideal portfolio of stocks to maximize profit."},{"metadata":{"_uuid":"ef167f97968835ed9efd933e940ed7a39b2ab041"},"cell_type":"markdown","source":"<a id='corelation'></a>\n## Corelation Analysis"},{"metadata":{"_uuid":"1ee5a9679a50261fd928afbabf135d78ded4e5b6"},"cell_type":"markdown","source":"Let us now try to find some corelation between the growth vs time of each stock in the dataset"},{"metadata":{"trusted":true,"_uuid":"acd9d9bfb4503593de84af7b1bd4545f365d3f98"},"cell_type":"code","source":"corr = df.pivot('Date', 'Name', 'Growth').corr()\nsns.heatmap(corr)","execution_count":51,"outputs":[]},{"metadata":{"_uuid":"05d5f225edf0b2407662791e5380153bee5f104c"},"cell_type":"markdown","source":"Although we can see some positive and negative corelations, the graph above is very dense. Let's us just focus on high positive and high negative corelations."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"45acc66bfafc1152f25b895b44e3df6b3a8c9993"},"cell_type":"code","source":"def unique_corelations(indices):\n    mapping = {}\n    for record in indices:\n        (stock_a, stock_b) = record\n        value_list = mapping.get(stock_a)\n        if value_list:\n            if stock_b not in value_list:\n                value_list.append(stock_b)\n                mapping.update({stock_a: value_list})\n        else:\n            mapping.update({stock_a: [stock_b]})\n\n    return mapping\n\ndef filter_corelations_positive(corr, threshold=0.9):\n    indices = np.where(corr > threshold)\n    indices = [(corr.index[x], corr.columns[y]) for x, y in zip(*indices)\n                                        if x != y and x < y]\n    mapping = unique_corelations(indices)\n    return mapping\n    \ndef filter_corelations_negative(corr, threshold=-0.8):\n    indices = np.where(corr < threshold)\n    indices = [(corr.index[x], corr.columns[y]) for x, y in zip(*indices)\n                                        if x != y and x < y]\n    mapping = unique_corelations(indices)\n    return mapping","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f00d9a5030d820cf94d4470604b0e7562b03b275"},"cell_type":"code","source":"filter_corelations_positive(corr, threshold=0.95)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ff009668eb104dcad92f61665ea5800411f7568"},"cell_type":"code","source":"filter_corelations_negative(corr, -0.1)","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"a468a1390c7687e71851ea85bde3c94d646a5cb6"},"cell_type":"markdown","source":"From the above results, we can note the following:-\n- There is a **Strong Positive** corelation in the stock growth of GOOGL with MSFT, NKE, etc.\n- There is a **Weak Negative** corelation in the stock growth of GE with IBM and MCD."},{"metadata":{"_uuid":"0228c07018ef2454ec43a6780151574ff2988380"},"cell_type":"markdown","source":"Let us try to forecast the prices of the Google Stock(GOOGL) and measure how close we came to the actual value."},{"metadata":{"_uuid":"58cff53dced5fc4b25c98ea46468d4ca011f98e0"},"cell_type":"markdown","source":"<a id='data_modelling'></a>\n## Data Modelling"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3487e6cd62ba03b45de7af1d0260cfbdd7582165"},"cell_type":"code","source":"google_df = df[df.Name == 'GOOGL']","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"941cc380589b1e11864bb3ac7d5776121483fd0a"},"cell_type":"code","source":"gdf = google_df[['Date', 'Price']].sort_values('Date')","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"5b363f0c3f86f6e2ff8be2592f14b2a657dd10db"},"cell_type":"markdown","source":"<a id='model_selection'></a>\n## Model Selection"},{"metadata":{"_uuid":"62d8cbd27037325ffce2f3ac26d9d28c59b0e34f"},"cell_type":"markdown","source":"As this is a time-series problem, we can use one of the following models to solve it:\n- ARIMA/ARMA: Auto-Regressive Moving Average models are a class of model that captures a suite of different standard temporal structures in time series data.\n- LSTM: Long-Short-Term_memory networks are a form of Recurrent Neural Networks. Few advantages of neural nets are:\n    - Neural networks can model any non-linear function\n    - Neural networks give good results without much parameter tuning\n"},{"metadata":{"_uuid":"cc3a5b050130cc320614686efa59b2c447ce3fae"},"cell_type":"markdown","source":"Hence, We will choose LSTM's as our model for forecasting stock prices."},{"metadata":{"_uuid":"db04edbf33b60f24118f29a102c2d53d7f298ee6"},"cell_type":"markdown","source":"We will try to predict the `Price` of the Google based on the previous 60 values(i.e stock prices on the previous 30 days) "},{"metadata":{"_uuid":"8ef4504c7559f6a5f4c39f7368c20b8731af9398"},"cell_type":"markdown","source":"<a id='fetch_data'></a>\n## Fetch Data"},{"metadata":{"_uuid":"6222844fd45ab7e9331d19bc8e0e1a9214880aa3"},"cell_type":"markdown","source":"We will only use the `Price` column to forecast the future stock price for simplicity. We will ignore all of the other columns."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6a0ce13de00226685e5f1acdc30f356ee9a7409b"},"cell_type":"code","source":"training_set = gdf[gdf.Date.dt.year != 2017].Price.values","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1fb7dd9f2078329b442694410c1a333cc7a143ff"},"cell_type":"code","source":"test_set =  gdf[gdf.Date.dt.year == 2017].Price.values","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1179234870560563e218af7fc3a8f5a669ef15cd"},"cell_type":"code","source":"print(\"Training set size: \",training_set.size)\nprint(\"Test set size: \", test_set.size)","execution_count":59,"outputs":[]},{"metadata":{"_uuid":"d453211fd569ef72623658dfc1172f08191d214f"},"cell_type":"markdown","source":"<a id='feature_scaling'></a>\n## Feature Scaling"},{"metadata":{"_uuid":"cc33d3703f7c193c42f4fc1e6deb343e8f0570ff"},"cell_type":"markdown","source":"As the amount of stock prices vary by a huge margin, we will scale the prices to be in the 0-1 range"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f245afed5ee232bb338f494f089e52d25adab5c1"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1f504fd3f19ea73aec161354e7d16a107e40ec4d"},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bf8e3bbb47b98bd8f5623d2af51398e2a6ddaca8"},"cell_type":"code","source":"training_set_scaled = scaler.fit_transform(training_set.reshape(-1, 1))","execution_count":62,"outputs":[]},{"metadata":{"_uuid":"4913d4842a53cc0350b05548c53ad9a80b1047af"},"cell_type":"markdown","source":"<a id='train_test_split'></a>\n## Train and Test timestep data creation"},{"metadata":{"_uuid":"42dec87bffa9acac901de35810a8db1936ab7c8b"},"cell_type":"markdown","source":"For training, we will use previous 30 stock values to predict the stock price at time t. For this, we have to create our training and test set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8a066fbc15aa49a92cd63c210a31d7d2936e94b8"},"cell_type":"code","source":"def create_train_data(training_set_scaled):\n    X_train, y_train = [], []\n    for i in range(30, training_set_scaled.size):\n        X_train.append(training_set_scaled[i-30: i])\n        y_train.append(training_set_scaled[i])\n    # Converting list to numpy arrays\n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n    return X_train, y_train","execution_count":63,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ef1a96912059565bdeea4d0980e2c20d9f270d6d"},"cell_type":"code","source":"X_train, y_train = create_train_data(training_set_scaled)","execution_count":64,"outputs":[]},{"metadata":{"_uuid":"8127843bd425ee026f918287934bc844f3956929"},"cell_type":"markdown","source":"Similarly, we'll create our test data set. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e04452a73f653a40568250533fe2f0274299887a"},"cell_type":"code","source":"def create_test_data():\n    X_test = []\n    inputs = gdf[len(gdf) - len(test_set) - 30:].Price.values\n    inputs = scaler.transform(inputs.reshape(-1, 1))\n    for i in range(30, test_set.size+30): # Range of the number of values in the training dataset\n        X_test.append(inputs[i - 30: i, 0])\n    X_test = np.array(X_test)\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n    return X_test","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c9089c1e5bba2312fe82868fc8c69451d7136ea8"},"cell_type":"code","source":"X_test = create_test_data()","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5071d16948c1663180594b5f1c85f2003dde5d80"},"cell_type":"code","source":"X_test.shape","execution_count":67,"outputs":[]},{"metadata":{"_uuid":"e33b584a3b0a1859a2b7a89bde38ec96e1a094a5"},"cell_type":"markdown","source":"<a id='forecasting'></a>\n## Forecasting"},{"metadata":{"_uuid":"541e8b56ea31ca9f5216319c69c593a598b5c225"},"cell_type":"markdown","source":"Let us first start with a very simple model. We will use a single LSTM layer."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"36e7990175971db1a8ca27ed1d8183ae57226344"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM","execution_count":68,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ae3351a557f249e52b42b84d0dd298514e2c0111"},"cell_type":"code","source":"def create_simple_model():\n    model = Sequential()\n    model.add(LSTM(units = 10, return_sequences = False, input_shape = (X_train.shape[1], 1)))\n    model.add(Dense(units = 1))\n    return model","execution_count":69,"outputs":[]},{"metadata":{"_uuid":"d01223de3edc0ec5669ce101703b2b519c28e0b9"},"cell_type":"markdown","source":"We now need to pick the optimizer for our model and a function to measure how well the model is doing i.e loss. We will pick RMSE as the loss function and Sigmoid Gradient Descent(SGD) as our optimizer with default learning rate(i.e 0.01)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0051a10de438992ceaa6d00c339f68eb6811fff7"},"cell_type":"code","source":"def compile_and_run(model, epochs=50, batch_size=64):\n    model.compile(metrics=['accuracy'], optimizer='adam', loss='mean_squared_error')\n    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=3)\n    return history","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"531fb175886a2a3bff532e14a393c3e0f0afc249"},"cell_type":"code","source":"def plot_metrics(history):\n    metrics_df = pd.DataFrame(data={\"loss\": history.history['loss']})\n    metrics_df.plot()","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4c306915de59f78913938b365dd8ba0083f26f8"},"cell_type":"code","source":"simple_model = create_simple_model()\nhistory = compile_and_run(simple_model, epochs=20)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcd4d571ec472b80f6d73ef981c8568d7b45423e"},"cell_type":"code","source":"plot_metrics(history)","execution_count":74,"outputs":[]},{"metadata":{"_uuid":"c2749a1b9452e194fd7828435e5a27f19eedccf2"},"cell_type":"markdown","source":"Let us now use the model on the test set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aea51e8b7691dd3031ef405c58b493f2dbf513d6"},"cell_type":"code","source":"def make_predictions(X_test, model):\n    y_pred = model.predict(X_test)\n    final_predictions = scaler.inverse_transform(y_pred)\n    fp = np.ndarray.flatten(final_predictions)\n    ap = np.ndarray.flatten(test_set)\n    pdf = pd.DataFrame(data={'Actual': ap, 'Predicted': fp})\n    ax = pdf.plot()","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9284d466ddc753b50a46553a00d625776a98afa0"},"cell_type":"code","source":"make_predictions(X_test, simple_model)","execution_count":76,"outputs":[]},{"metadata":{"_uuid":"a8e6f0e1110e33427bd26c65746d8fc6f439f250"},"cell_type":"markdown","source":"As we can see from the image above, although our model seems to have found some trend in the prices, it it _very_ far away from the actual stock value. Hence, this model cannot be used in a production environment.\n\n**Question**: Can we improve this model?\n\nLets find out."},{"metadata":{"_uuid":"a986ea6ac5d47437cfb31ca32d5e202cdc10fbb1"},"cell_type":"markdown","source":"<a id='dl'></a>\n## Deep Neural Nets"},{"metadata":{"_uuid":"8c7f75d5bcc2910094d294280e4045617a47344b"},"cell_type":"markdown","source":"As always, here is the solution to our problem"},{"metadata":{"_uuid":"be08943870f54092d6fb989376e8f61978dc95fd"},"cell_type":"markdown","source":"![DL](https://s14-eu5.ixquick.com/cgi-bin/serveimage?url=https%3A%2F%2Fmemegenerator.net%2Fimg%2Finstances%2F49099937%2Fwe-need-to-go-deeper.jpg&sp=820b593abca83c69cfd8fe7944c66fce)"},{"metadata":{"_uuid":"8dd01ed6fdbe4006bf9a2f534142d9619ca18095"},"cell_type":"markdown","source":"Deep neural nets can capture trends over a largely spread dataset and could improve our model.\nFor this problem of forecasting, we will use a stacked LSTM(i.e multiple LSTM layers instead of 1). \nFurther, we will also increase the number of units per LSTM cell to 50."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b67239d443810760b34c296a5880d2233a7ca170"},"cell_type":"code","source":"def create_dl_model():\n    model = Sequential()\n\n    # Adding the first LSTM layer\n    model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n\n    # Adding a second LSTM layer\n    model.add(LSTM(units = 50, return_sequences = True))\n    \n    # Adding a third LSTM layer\n    model.add(LSTM(units = 50, return_sequences = True))\n\n    # Adding a fourth LSTM layer\n    model.add(LSTM(units = 50))\n\n    # Adding the output layer\n    model.add(Dense(units = 1))\n    return model","execution_count":87,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d55a091a8482e1c79151e54d90c08a9dfafd92fb"},"cell_type":"code","source":"dl_model = create_dl_model()","execution_count":81,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbe0ae904583382e2f7fa60ac809f50d96828e25"},"cell_type":"code","source":"dl_model.summary()","execution_count":82,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79e07ed7efd0b999ab9888fd095a50b5cb04f4f0"},"cell_type":"code","source":"history = compile_and_run(dl_model, epochs=20)","execution_count":83,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7ac930ea02c55e0aa3c3943202281641094cf1d"},"cell_type":"code","source":"plot_metrics(history)","execution_count":85,"outputs":[]},{"metadata":{"_uuid":"64dcb927c3bf63ccb3fad92198f9b510c90f0f99"},"cell_type":"markdown","source":"As expected, we see that the overall loss of the model reducing until a minima is reached. After that, the loss just stays constant."},{"metadata":{"_uuid":"40b9699a68ed499c3ae50e4ec9b6fbe0aad29f84"},"cell_type":"markdown","source":"<a id='prediction_analysis'></a>\n## Prediction Analysis"},{"metadata":{"_uuid":"ae06c100bef45dbd5a35fbe892c945622c4ac4b4"},"cell_type":"markdown","source":"Let us try our deep neural net on the test set."},{"metadata":{"trusted":true,"_uuid":"b2a15de7696ee0265e65d2c6e213913c0d4a217f"},"cell_type":"code","source":"make_predictions(X_test, dl_model)","execution_count":86,"outputs":[]},{"metadata":{"_uuid":"4fce276e746db278dacd5e397c22dbd60d74dec7"},"cell_type":"markdown","source":"As we can see, the deep neural net is a significant boost from our simple model. It has determined that the stock price is indeed related to the previous stock prices, and surprisngly, it is very accurate, so much so that at various points it is actually equal to the exact value of the stock on that day!"},{"metadata":{"_uuid":"4d1c0fb78ee781d36a50fe35119757c7570cfd81"},"cell_type":"markdown","source":"We could further improve this model by:\n\n- **Deeper network** - Deep Neural Networks can learn relationships between data points seperated by a large time frame.\n- **Dropout** - Adding a dropout layer would help prevent overfitting and stabalize the loss curves, which could give a better generalized model.\n- **Training for longer** - Deep neural nets work better when they are trained for longer tend to work better. However, we must be careful not to overfit.\n- **Adaptive Optimizers** - We could also use the Adam optimizer instead of SGD, which incorporates adaptive learning rates based on momentum. Adaptive optimizers should work better than SGD for this problem.\n- **Hyper-parameter tuning** - Tuning the hyper-parameters is one of the simplest ways in which we can improve the network. We could use SGD with Restarts(part of the Fast.ai library) to help find the optimal learning rate, experiment with the number of units in each LSTM layer, etc."},{"metadata":{"_uuid":"6ada83ba0cb04a96608f3eeab1cd8f42f254e733"},"cell_type":"markdown","source":"<a id='conclusion'></a>\n## Conclusion"},{"metadata":{"_uuid":"10686701a6c55384bc475789d8f7306fa81a7d78"},"cell_type":"markdown","source":"In this notebook, we have acheived the following:\n- Successfully analyzed the trends present in stock market prices of various companies and concluded that there is indeed a temporal relationship between these prices. \n- Devised a model capable of reliably forecasting the stock prices of a company, thereby providing a tool to maximize profits.\n- Discussed possible implementation details to deploy such a model at scale and make it available to a larger number of people."},{"metadata":{"_uuid":"ab0b4973de7bfc273a4cb75d3e120e456a60be04"},"cell_type":"markdown","source":"Please let me know about the areas where the solution could be improved. As always, please upvote the kernel if you find it useful. Cheers! :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}